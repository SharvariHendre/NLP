{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d099a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bc5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "    \"Deep learning and artificial intelligence are advancing rapidly.\",\n",
    "    \"Data science and machine learning are transforming industries.\",\n",
    "    \"Natural language processing is a subfield of AI.\",\n",
    "    \"The application of AI in healthcare is growing.\",\n",
    "    \"AI in finance is a game-changer.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Data science involves the use of machine learning algorithms.\",\n",
    "    \"Healthcare data is becoming more valuable with AI tools.\"\n",
    "]\n",
    "\n",
    "# Text Preprocessing (Vectorization using TF-IDF)\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ffb0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "learning machine artificial intelligence science\n",
      "Topic #2:\n",
      "ai healthcare growing application valuable\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Apply NMF for Topic Modeling\n",
    "n_topics = 2  # Choose the number of topics\n",
    "\n",
    "nmf_model = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf_model.fit_transform(X)  # Document-Topic Matrix\n",
    "H = nmf_model.components_  # Topic-Term Matrix\n",
    "\n",
    "# Display the top words in each topic\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words=5):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx + 1}:\")\n",
    "        top_words_idx = topic.argsort()[:-no_top_words - 1:-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        print(\" \".join(top_words))\n",
    "\n",
    "# Display Topics\n",
    "display_topics(nmf_model, feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97d993f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Error (Mean Squared Error): 0.0211\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Evaluate Reconstruction Error\n",
    "X_reconstructed = np.dot(W, H)\n",
    "reconstruction_error = mean_squared_error(X.toarray(), X_reconstructed)\n",
    "\n",
    "print(f\"Reconstruction Error (Mean Squared Error): {reconstruction_error:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f28f0a",
   "metadata": {},
   "source": [
    "B) Word Disambiguation using WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b44dae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d2f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Required Libraries\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')  # Download the WordNet lexicon and its multilingual version\n",
    "\n",
    "# Example sentence\n",
    "sentence = \"The bank will not allow withdrawal after hours.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74531b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Sense: deposit.v.02\n",
      "Definition: put into a bank account\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Word Sense Disambiguation using Lesk Algorithm\n",
    "def disambiguate_word(context, word):\n",
    "    # Use the Lesk algorithm to get the most likely sense of the word\n",
    "    sense = lesk(context, word)\n",
    "    if sense:\n",
    "        return sense.name(), sense.definition()\n",
    "    else:\n",
    "        return \"No sense found\", None\n",
    "\n",
    "# Disambiguate the word 'bank' in the context of the sentence\n",
    "context = nltk.word_tokenize(sentence)\n",
    "word = 'bank'\n",
    "sense_name, sense_definition = disambiguate_word(context, word)\n",
    "\n",
    "print(f\"Word Sense: {sense_name}\")\n",
    "print(f\"Definition: {sense_definition}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b564f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
